ğŸ“ Student Depression Prediction â€“ UÃ§tan Uca MLOps Projesi

Bu proje, Ã¶ÄŸrencilerde depresyon durumunu tahmin etmek iÃ§in geliÅŸtirilmiÅŸ, uÃ§tan uca bir MLOps tabanlÄ± makine Ã¶ÄŸrenmesi sistemidir.

Projede; verinin alÄ±nmasÄ±ndan baÅŸlayarak model eÄŸitimi, deney takibi, artefact yÃ¶netimi ve canlÄ± ortama otomatik daÄŸÄ±tÄ±ma kadar tÃ¼m sÃ¼reÃ§ler gerÃ§ek bir Ã¼retim ortamÄ±na uygun ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.

ğŸš€ Proje AmacÄ±

Bu projenin amacÄ±;

Ã¶ÄŸrencilerin akademik ve yaÅŸam alÄ±ÅŸkanlÄ±klarÄ±na ait Ã¶zellikleri kullanarak:

Ã¶ÄŸrencinin depresyonda olup olmadÄ±ÄŸÄ±nÄ± tahmin eden bir makine Ã¶ÄŸrenmesi sistemi geliÅŸtirmektir.

SÄ±nÄ±flandÄ±rma problemi:

0 â†’ Depresyonda deÄŸil

1 â†’ Depresyonda

ğŸ“Š Veri Seti

Model aÅŸaÄŸÄ±daki Ã¶zellikleri kullanÄ±r:

Age

Gender

Department

CGPA

Sleep duration

Study hours

Social media hours

Physical activity

Stress level

Hedef kolon: Ã¶ÄŸrencinin depresyon durumu.

ğŸ§  KullanÄ±lan Teknolojiler

Python

Scikit-learn

MLflow

DagsHub

Docker

Flask

GitHub Actions

AWS EC2

AWS ECR

AWS S3


ğŸ— Genel Mimari

Proje aÅŸaÄŸÄ±daki uÃ§tan uca pipeline yapÄ±sÄ±na sahiptir:

Data Ingestion
      â†“
Data Validation
      â†“
Data Transformation
      â†“
Model Training
      â†“
Model Evaluation
      â†“
Artifact kayÄ±tlarÄ± (DagsHub + S3)


ğŸ”„ Veri DÃ¶nÃ¼ÅŸtÃ¼rme (Data Transformation)

Veri Ã¶n iÅŸleme sÃ¼reci ColumnTransformer kullanÄ±larak yapÄ±lmaktadÄ±r.

SayÄ±sal deÄŸiÅŸkenler iÃ§in:

Median imputation

StandardScaler

Kategorik deÄŸiÅŸkenler iÃ§in:

Most frequent imputation

OneHotEncoder

EÄŸitilen preprocessing pipeline:

pickle olarak kaydedilir

inference sÄ±rasÄ±nda tekrar kullanÄ±lÄ±r.

DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ veri setleri:

train_transformed.csv

test_transformed.csv

olarak artefact klasÃ¶rÃ¼ne yazÄ±lÄ±r.

ğŸ¤– Model EÄŸitimi

AynÄ± veri Ã¼zerinde birden fazla model eÄŸitilmekte ve en iyi model otomatik olarak seÃ§ilmektedir.

EÄŸitilen modeller:

RandomForestClassifier

AdaBoostClassifier

GradientBoostingClassifier

Her model iÃ§in:

GridSearchCV ile hiperparametre aramasÄ± yapÄ±lÄ±r

Test verisi Ã¼zerinde accuracy hesaplanÄ±r

En iyi accuracy deÄŸerine sahip model seÃ§ilir

SeÃ§ilen model:

pickle olarak kaydedilir

parametreleri ayrÄ± bir JSON dosyasÄ±na yazÄ±lÄ±r.

ğŸ“ˆ Model DeÄŸerlendirme ve Deney Takibi

Model deÄŸerlendirme aÅŸamasÄ±nda:

Accuracy

Confusion Matrix

hesaplanmaktadÄ±r.

TÃ¼m deneyler MLflow ile takip edilir.

MLflow altyapÄ±sÄ± DagsHub Ã¼zerinden Ã§alÄ±ÅŸmaktadÄ±r.

Her run sÄ±rasÄ±nda:

accuracy

confusion matrix

model adÄ±

model hiperparametreleri

eÄŸitilmiÅŸ model

MLflowâ€™a loglanÄ±r.

â˜ï¸ Artifact YÃ¶netimi

Bu projede artefactâ€™lar iki farklÄ± ortamda tutulur.

âœ” DagsHub

MLflow experiment kayÄ±tlarÄ±

model artefactâ€™larÄ±

âœ” AWS S3

EÄŸitim tamamlandÄ±ktan sonra:

artifacts/
klasÃ¶rÃ¼nÃ¼n tamamÄ± otomatik olarak S3 bucketâ€™a senkronize edilir.


ğŸŒ API Servisi (Flask)

Model servis tarafÄ± Flask ile yazÄ±lmÄ±ÅŸtÄ±r.

Endpointâ€™ler
Ana sayfa

GET /
Tahmin formunu gÃ¶sterir.

Tahmin

POST /predict

Formdan gelen veriler ile tahmin yapar.

EÄŸitim

GET /train

TÃ¼m training pipelineâ€™Ä±nÄ± tetikler.

ğŸ³ Docker

Uygulama Docker container iÃ§erisinde Ã§alÄ±ÅŸmaktadÄ±r.

Flask uygulamasÄ± container iÃ§inde:

0.0.0.0:8080
portunda dinler.

ğŸ” CI / CD SÃ¼reci

GitHub Actions Ã¼zerinden 3 aÅŸamalÄ± bir pipeline kurulmuÅŸtur.

1ï¸âƒ£ Continuous Integration

Repository checkout

Lint

Unit test adÄ±mlarÄ±

2ï¸âƒ£ Continuous Delivery

Docker image build edilir

AWS ECRâ€™a push edilir

3ï¸âƒ£ Continuous Deployment

AWS EC2 Ã¼zerinde Ã§alÄ±ÅŸan self-hosted runner kullanÄ±lÄ±r

ECRâ€™dan en gÃ¼ncel image Ã§ekilir

Container ayaÄŸa kaldÄ±rÄ±lÄ±r

â˜ï¸ Bulut AltyapÄ±sÄ±

AWS EC2 â†’ uygulamanÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ± sunucu

GitHub self-hosted runner â†’ EC2 Ã¼zerinde Ã§alÄ±ÅŸÄ±r

AWS ECR â†’ Docker image deposu

AWS S3 â†’ tÃ¼m artifacts klasÃ¶rÃ¼ saklanÄ±r

ğŸ§ª Deney Takibi

TÃ¼m eÄŸitim sÃ¼reÃ§leri:

MLflow

DagsHub

Ã¼zerinden takip edilir.

Her eÄŸitim Ã§alÄ±ÅŸmasÄ± iÃ§in:

metrikler

parametreler

confusion matrix

model dosyasÄ±

kayÄ±t altÄ±na alÄ±nÄ±r.

ğŸ“ Proje KlasÃ¶r YapÄ±sÄ±



```text
student-depression-mlops-project/
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ objects/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ reports/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_validation.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â”œâ”€â”€ model_train.py
â”‚   â”‚   â””â”€â”€ model_eval.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ datapipeline.py
â”‚   â”‚   â””â”€â”€ modelpredictPipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ entity/
â”‚   â”‚   â”œâ”€â”€ artifacts_entity.py
â”‚   â”‚   â””â”€â”€ config_entity.py
â”‚   â”‚
â”‚   â”œâ”€â”€ cloud/
â”‚   â”‚   â””â”€â”€ s3_syncer.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ main.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”‚
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ workflow.yml


â–¶ï¸ Lokal Ã‡alÄ±ÅŸtÄ±rma
Gerekli paketler

pip install -r requirements.txt


EÄŸitim pipelineâ€™Ä±nÄ± Ã§alÄ±ÅŸtÄ±rmak

python main.py

APIâ€™yi Ã§alÄ±ÅŸtÄ±rmak

python app.py

TarayÄ±cÄ±dan:

http://localhost:8080  (deploy sonrasÄ± url:8080)


ğŸ” Ortam DeÄŸiÅŸkenleri

AÅŸaÄŸÄ±daki bilgiler GitHub Actions secrets olarak tanÄ±mlanmÄ±ÅŸtÄ±r:

AWS_ACCESS_KEY_ID

AWS_SECRET_ACCESS_KEY

AWS_REGION

ECR_REPOSITORY_NAME

â­ Projenin Ã–ne Ã‡Ä±kan NoktalarÄ±

Tamamen modÃ¼ler MLOps pipeline mimarisi

Otomatik model seÃ§imi (GridSearchCV)

MLflow + DagsHub ile deney takibi

Artifactâ€™larÄ±n S3 Ã¼zerinde merkezi olarak tutulmasÄ±

Docker ile containerlaÅŸtÄ±rÄ±lmÄ±ÅŸ servis

GitHub Actions ile uÃ§tan uca CI/CD

Self-hosted runner ile gerÃ§ek production benzeri deployment

ğŸ‘¤ GeliÅŸtirici

Muharrem AydoÄŸan

Bu proje, gerÃ§ek hayattaki MLOps sÃ¼reÃ§lerini gÃ¶stermek amacÄ±yla;
model yaÅŸam dÃ¶ngÃ¼sÃ¼, deney takibi ve Ã¼retim ortamÄ±na daÄŸÄ±tÄ±m adÄ±mlarÄ±nÄ± kapsayacak ÅŸekilde geliÅŸtirilmiÅŸtir.
